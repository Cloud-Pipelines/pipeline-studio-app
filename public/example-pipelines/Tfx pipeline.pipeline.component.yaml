name: Tfx pipeline
metadata:
  annotations:
    author: Alexey Volkov <alexey.volkov@ark-kun.com>
implementation:
  graph:
    tasks:
      CsvExampleGen:
        componentRef:
          digest: cfa163801444dc433545cadaa0021566683d31e8ca747858c538b98f280af8cb
          url: https://raw.githubusercontent.com/kubeflow/pipelines/9b0d47a226c61f96e1ebe7a8ba427df38f8734e1/components/deprecated/tfx/ExampleGen/CsvExampleGen/component.yaml
          spec:
            name: CsvExampleGen
            inputs:
              - name: input_base
                type: String
              - name: input_config
                type:
                  JsonObject:
                    data_type: proto:tfx.components.example_gen.Input
              - name: output_config
                type:
                  JsonObject:
                    data_type: proto:tfx.components.example_gen.Output
              - name: range_config
                type:
                  JsonObject:
                    data_type: proto:tfx.configs.RangeConfig
                optional: true
            outputs:
              - name: examples
                type: Examples
            implementation:
              container:
                image: tensorflow/tfx:0.29.0
                command:
                  - sh
                  - '-ec'
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def _make_parent_dirs_and_return_path(file_path: str):
                        import os
                        os.makedirs(os.path.dirname(file_path), exist_ok=True)
                        return file_path

                    def CsvExampleGen(
                        examples_path,
                        input_base,
                        input_config,
                        output_config,
                        range_config = None,
                    ):
                        from tfx.components.example_gen.csv_example_gen.component import CsvExampleGen as component_class

                        #Generated code
                        import os
                        import tempfile
                        from tensorflow.io import gfile
                        from google.protobuf import json_format, message
                        from tfx.types import channel_utils, artifact_utils
                        from tfx.components.base import base_executor

                        arguments = locals().copy()

                        component_class_args = {}

                        for name, execution_parameter in component_class.SPEC_CLASS.PARAMETERS.items():
                            argument_value = arguments.get(name, None)
                            if argument_value is None:
                                continue
                            parameter_type = execution_parameter.type
                            if isinstance(parameter_type, type) and issubclass(parameter_type, message.Message):
                                argument_value_obj = parameter_type()
                                json_format.Parse(argument_value, argument_value_obj)
                            else:
                                argument_value_obj = argument_value
                            component_class_args[name] = argument_value_obj

                        for name, channel_parameter in component_class.SPEC_CLASS.INPUTS.items():
                            artifact_path = arguments.get(name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel_parameter.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                if channel_parameter.type.PROPERTIES and 'split_names' in channel_parameter.type.PROPERTIES:
                                    # Recovering splits
                                    subdirs = gfile.listdir(artifact_path)
                                    # Workaround for https://github.com/tensorflow/tensorflow/issues/39167
                                    subdirs = [subdir.rstrip('/') for subdir in subdirs]
                                    split_names = [subdir.replace('Split-', '') for subdir in subdirs]
                                    artifact.split_names = artifact_utils.encode_split_names(sorted(split_names))
                                component_class_args[name] = channel_utils.as_channel([artifact])

                        component_class_instance = component_class(**component_class_args)

                        input_dict = channel_utils.unwrap_channel_dict(component_class_instance.inputs.get_all())
                        output_dict = {}
                        exec_properties = component_class_instance.exec_properties

                        # Generating paths for output artifacts
                        for name, channel in component_class_instance.outputs.items():
                            artifact_path = arguments.get('output_' + name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                artifact_list = [artifact]
                                channel._artifacts = artifact_list
                                output_dict[name] = artifact_list

                        print('component instance: ' + str(component_class_instance))

                        executor_context = base_executor.BaseExecutor.Context(
                            beam_pipeline_args=arguments.get('beam_pipeline_args'),
                            tmp_dir=tempfile.gettempdir(),
                            unique_id='tfx_component',
                        )
                        executor = component_class_instance.executor_spec.executor_class(executor_context)
                        executor.Do(
                            input_dict=input_dict,
                            output_dict=output_dict,
                            exec_properties=exec_properties,
                        )

                    import argparse
                    _parser = argparse.ArgumentParser(prog='CsvExampleGen', description='')
                    _parser.add_argument("--input-base", dest="input_base", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--input-config", dest="input_config", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--output-config", dest="output_config", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--range-config", dest="range_config", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--examples", dest="examples_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parsed_args = vars(_parser.parse_args())

                    _outputs = CsvExampleGen(**_parsed_args)
                args:
                  - '--input-base'
                  - inputValue: input_base
                  - '--input-config'
                  - inputValue: input_config
                  - '--output-config'
                  - inputValue: output_config
                  - if:
                      cond:
                        isPresent: range_config
                      then:
                        - '--range-config'
                        - inputValue: range_config
                  - '--examples'
                  - outputPath: examples
        arguments:
          input_base: gs://ml-pipeline-playground/tensorflow-tfx-repo/tfx/components/testdata/external/csv
          input_config: '{"splits": [{"name": "data", "pattern": "*.csv"}]}'
          output_config: '{"splitConfig": {"splits": [{"name": "train", "hash_buckets": 2}, {"name": "eval", "hash_buckets": 1}]}}'
        annotations:
          editor.position: '{"x":-390,"y":210}'
      StatisticsGen:
        componentRef:
          digest: b0fb8d3c20937a1da14ea30ebf3a3dfda31ec3d6e1f7fe57b001f40087684c36
          url: https://raw.githubusercontent.com/kubeflow/pipelines/9b0d47a226c61f96e1ebe7a8ba427df38f8734e1/components/deprecated/tfx/StatisticsGen/component.yaml
          spec:
            name: StatisticsGen
            inputs:
              - name: examples
                type: Examples
              - name: schema
                type: Schema
                optional: true
              - name: exclude_splits
                type: String
                optional: true
            outputs:
              - name: statistics
                type: ExampleStatistics
            implementation:
              container:
                image: tensorflow/tfx:0.29.0
                command:
                  - sh
                  - '-ec'
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def _make_parent_dirs_and_return_path(file_path: str):
                        import os
                        os.makedirs(os.path.dirname(file_path), exist_ok=True)
                        return file_path

                    def StatisticsGen(
                        examples_path,
                        statistics_path,
                        schema_path = None,
                        exclude_splits = None,
                    ):
                        from tfx.components.statistics_gen.component import StatisticsGen as component_class

                        #Generated code
                        import os
                        import tempfile
                        from tensorflow.io import gfile
                        from google.protobuf import json_format, message
                        from tfx.types import channel_utils, artifact_utils
                        from tfx.components.base import base_executor

                        arguments = locals().copy()

                        component_class_args = {}

                        for name, execution_parameter in component_class.SPEC_CLASS.PARAMETERS.items():
                            argument_value = arguments.get(name, None)
                            if argument_value is None:
                                continue
                            parameter_type = execution_parameter.type
                            if isinstance(parameter_type, type) and issubclass(parameter_type, message.Message):
                                argument_value_obj = parameter_type()
                                json_format.Parse(argument_value, argument_value_obj)
                            else:
                                argument_value_obj = argument_value
                            component_class_args[name] = argument_value_obj

                        for name, channel_parameter in component_class.SPEC_CLASS.INPUTS.items():
                            artifact_path = arguments.get(name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel_parameter.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                if channel_parameter.type.PROPERTIES and 'split_names' in channel_parameter.type.PROPERTIES:
                                    # Recovering splits
                                    subdirs = gfile.listdir(artifact_path)
                                    # Workaround for https://github.com/tensorflow/tensorflow/issues/39167
                                    subdirs = [subdir.rstrip('/') for subdir in subdirs]
                                    split_names = [subdir.replace('Split-', '') for subdir in subdirs]
                                    artifact.split_names = artifact_utils.encode_split_names(sorted(split_names))
                                component_class_args[name] = channel_utils.as_channel([artifact])

                        component_class_instance = component_class(**component_class_args)

                        input_dict = channel_utils.unwrap_channel_dict(component_class_instance.inputs.get_all())
                        output_dict = {}
                        exec_properties = component_class_instance.exec_properties

                        # Generating paths for output artifacts
                        for name, channel in component_class_instance.outputs.items():
                            artifact_path = arguments.get('output_' + name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                artifact_list = [artifact]
                                channel._artifacts = artifact_list
                                output_dict[name] = artifact_list

                        print('component instance: ' + str(component_class_instance))

                        executor_context = base_executor.BaseExecutor.Context(
                            beam_pipeline_args=arguments.get('beam_pipeline_args'),
                            tmp_dir=tempfile.gettempdir(),
                            unique_id='tfx_component',
                        )
                        executor = component_class_instance.executor_spec.executor_class(executor_context)
                        executor.Do(
                            input_dict=input_dict,
                            output_dict=output_dict,
                            exec_properties=exec_properties,
                        )

                    import argparse
                    _parser = argparse.ArgumentParser(prog='StatisticsGen', description='')
                    _parser.add_argument("--examples", dest="examples_path", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--schema", dest="schema_path", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--exclude-splits", dest="exclude_splits", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--statistics", dest="statistics_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parsed_args = vars(_parser.parse_args())

                    _outputs = StatisticsGen(**_parsed_args)
                args:
                  - '--examples'
                  - inputPath: examples
                  - if:
                      cond:
                        isPresent: schema
                      then:
                        - '--schema'
                        - inputPath: schema
                  - if:
                      cond:
                        isPresent: exclude_splits
                      then:
                        - '--exclude-splits'
                        - inputValue: exclude_splits
                  - '--statistics'
                  - outputPath: statistics
        arguments:
          examples:
            taskOutput:
              taskId: CsvExampleGen
              outputName: examples
        annotations:
          editor.position: '{"x":30,"y":-20}'
      SchemaGen:
        componentRef:
          digest: 5c600fc95ce50348257eea2da6b134ba5ef308c88e3a9ac228e3a7847cdf59c6
          url: https://raw.githubusercontent.com/kubeflow/pipelines/9b0d47a226c61f96e1ebe7a8ba427df38f8734e1/components/deprecated/tfx/SchemaGen/component.yaml
          spec:
            name: SchemaGen
            inputs:
              - name: statistics
                type: ExampleStatistics
              - name: infer_feature_shape
                type: Integer
                optional: true
              - name: exclude_splits
                type: String
                optional: true
            outputs:
              - name: schema
                type: Schema
            implementation:
              container:
                image: tensorflow/tfx:0.29.0
                command:
                  - sh
                  - '-ec'
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def _make_parent_dirs_and_return_path(file_path: str):
                        import os
                        os.makedirs(os.path.dirname(file_path), exist_ok=True)
                        return file_path

                    def SchemaGen(
                        statistics_path,
                        schema_path,
                        infer_feature_shape = None,
                        exclude_splits = None,
                    ):
                        from tfx.components.schema_gen.component import SchemaGen as component_class

                        #Generated code
                        import os
                        import tempfile
                        from tensorflow.io import gfile
                        from google.protobuf import json_format, message
                        from tfx.types import channel_utils, artifact_utils
                        from tfx.components.base import base_executor

                        arguments = locals().copy()

                        component_class_args = {}

                        for name, execution_parameter in component_class.SPEC_CLASS.PARAMETERS.items():
                            argument_value = arguments.get(name, None)
                            if argument_value is None:
                                continue
                            parameter_type = execution_parameter.type
                            if isinstance(parameter_type, type) and issubclass(parameter_type, message.Message):
                                argument_value_obj = parameter_type()
                                json_format.Parse(argument_value, argument_value_obj)
                            else:
                                argument_value_obj = argument_value
                            component_class_args[name] = argument_value_obj

                        for name, channel_parameter in component_class.SPEC_CLASS.INPUTS.items():
                            artifact_path = arguments.get(name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel_parameter.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                if channel_parameter.type.PROPERTIES and 'split_names' in channel_parameter.type.PROPERTIES:
                                    # Recovering splits
                                    subdirs = gfile.listdir(artifact_path)
                                    # Workaround for https://github.com/tensorflow/tensorflow/issues/39167
                                    subdirs = [subdir.rstrip('/') for subdir in subdirs]
                                    split_names = [subdir.replace('Split-', '') for subdir in subdirs]
                                    artifact.split_names = artifact_utils.encode_split_names(sorted(split_names))
                                component_class_args[name] = channel_utils.as_channel([artifact])

                        component_class_instance = component_class(**component_class_args)

                        input_dict = channel_utils.unwrap_channel_dict(component_class_instance.inputs.get_all())
                        output_dict = {}
                        exec_properties = component_class_instance.exec_properties

                        # Generating paths for output artifacts
                        for name, channel in component_class_instance.outputs.items():
                            artifact_path = arguments.get('output_' + name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                artifact_list = [artifact]
                                channel._artifacts = artifact_list
                                output_dict[name] = artifact_list

                        print('component instance: ' + str(component_class_instance))

                        executor_context = base_executor.BaseExecutor.Context(
                            beam_pipeline_args=arguments.get('beam_pipeline_args'),
                            tmp_dir=tempfile.gettempdir(),
                            unique_id='tfx_component',
                        )
                        executor = component_class_instance.executor_spec.executor_class(executor_context)
                        executor.Do(
                            input_dict=input_dict,
                            output_dict=output_dict,
                            exec_properties=exec_properties,
                        )

                    import argparse
                    _parser = argparse.ArgumentParser(prog='SchemaGen', description='')
                    _parser.add_argument("--statistics", dest="statistics_path", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--infer-feature-shape", dest="infer_feature_shape", type=int, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--exclude-splits", dest="exclude_splits", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--schema", dest="schema_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parsed_args = vars(_parser.parse_args())

                    _outputs = SchemaGen(**_parsed_args)
                args:
                  - '--statistics'
                  - inputPath: statistics
                  - if:
                      cond:
                        isPresent: infer_feature_shape
                      then:
                        - '--infer-feature-shape'
                        - inputValue: infer_feature_shape
                  - if:
                      cond:
                        isPresent: exclude_splits
                      then:
                        - '--exclude-splits'
                        - inputValue: exclude_splits
                  - '--schema'
                  - outputPath: schema
        arguments:
          statistics:
            taskOutput:
              taskId: StatisticsGen
              outputName: statistics
        annotations:
          editor.position: '{"x":360,"y":170}'
      Transform:
        componentRef:
          digest: 3ffa018b909cb0c1717cae55bbb739a830b0d0a93f0c52188f1e2086e5cfce56
          url: https://raw.githubusercontent.com/kubeflow/pipelines/9b0d47a226c61f96e1ebe7a8ba427df38f8734e1/components/deprecated/tfx/Transform/component.yaml
          spec:
            name: Transform
            inputs:
              - name: examples
                type: Examples
              - name: schema
                type: Schema
              - name: analyzer_cache
                type: TransformCache
                optional: true
              - name: module_file
                type: String
                optional: true
              - name: preprocessing_fn
                type: String
                optional: true
              - name: force_tf_compat_v1
                type: Integer
                optional: true
              - name: custom_config
                type: String
                optional: true
              - name: splits_config
                type:
                  JsonObject:
                    data_type: proto:tfx.components.transform.SplitsConfig
                optional: true
            outputs:
              - name: transform_graph
                type: TransformGraph
              - name: transformed_examples
                type: Examples
              - name: updated_analyzer_cache
                type: TransformCache
            implementation:
              container:
                image: tensorflow/tfx:0.29.0
                command:
                  - sh
                  - '-ec'
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def _make_parent_dirs_and_return_path(file_path: str):
                        import os
                        os.makedirs(os.path.dirname(file_path), exist_ok=True)
                        return file_path

                    def Transform(
                        examples_path,
                        schema_path,
                        transform_graph_path,
                        transformed_examples_path,
                        updated_analyzer_cache_path,
                        analyzer_cache_path = None,
                        module_file = None,
                        preprocessing_fn = None,
                        force_tf_compat_v1 = None,
                        custom_config = None,
                        splits_config = None,
                    ):
                        from tfx.components.transform.component import Transform as component_class

                        #Generated code
                        import os
                        import tempfile
                        from tensorflow.io import gfile
                        from google.protobuf import json_format, message
                        from tfx.types import channel_utils, artifact_utils
                        from tfx.components.base import base_executor

                        arguments = locals().copy()

                        component_class_args = {}

                        for name, execution_parameter in component_class.SPEC_CLASS.PARAMETERS.items():
                            argument_value = arguments.get(name, None)
                            if argument_value is None:
                                continue
                            parameter_type = execution_parameter.type
                            if isinstance(parameter_type, type) and issubclass(parameter_type, message.Message):
                                argument_value_obj = parameter_type()
                                json_format.Parse(argument_value, argument_value_obj)
                            else:
                                argument_value_obj = argument_value
                            component_class_args[name] = argument_value_obj

                        for name, channel_parameter in component_class.SPEC_CLASS.INPUTS.items():
                            artifact_path = arguments.get(name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel_parameter.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                if channel_parameter.type.PROPERTIES and 'split_names' in channel_parameter.type.PROPERTIES:
                                    # Recovering splits
                                    subdirs = gfile.listdir(artifact_path)
                                    # Workaround for https://github.com/tensorflow/tensorflow/issues/39167
                                    subdirs = [subdir.rstrip('/') for subdir in subdirs]
                                    split_names = [subdir.replace('Split-', '') for subdir in subdirs]
                                    artifact.split_names = artifact_utils.encode_split_names(sorted(split_names))
                                component_class_args[name] = channel_utils.as_channel([artifact])

                        component_class_instance = component_class(**component_class_args)

                        input_dict = channel_utils.unwrap_channel_dict(component_class_instance.inputs.get_all())
                        output_dict = {}
                        exec_properties = component_class_instance.exec_properties

                        # Generating paths for output artifacts
                        for name, channel in component_class_instance.outputs.items():
                            artifact_path = arguments.get('output_' + name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                artifact_list = [artifact]
                                channel._artifacts = artifact_list
                                output_dict[name] = artifact_list

                        print('component instance: ' + str(component_class_instance))

                        executor_context = base_executor.BaseExecutor.Context(
                            beam_pipeline_args=arguments.get('beam_pipeline_args'),
                            tmp_dir=tempfile.gettempdir(),
                            unique_id='tfx_component',
                        )
                        executor = component_class_instance.executor_spec.executor_class(executor_context)
                        executor.Do(
                            input_dict=input_dict,
                            output_dict=output_dict,
                            exec_properties=exec_properties,
                        )

                    import argparse
                    _parser = argparse.ArgumentParser(prog='Transform', description='')
                    _parser.add_argument("--examples", dest="examples_path", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--schema", dest="schema_path", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--analyzer-cache", dest="analyzer_cache_path", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--module-file", dest="module_file", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--preprocessing-fn", dest="preprocessing_fn", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--force-tf-compat-v1", dest="force_tf_compat_v1", type=int, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--custom-config", dest="custom_config", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--splits-config", dest="splits_config", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--transform-graph", dest="transform_graph_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--transformed-examples", dest="transformed_examples_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--updated-analyzer-cache", dest="updated_analyzer_cache_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parsed_args = vars(_parser.parse_args())

                    _outputs = Transform(**_parsed_args)
                args:
                  - '--examples'
                  - inputPath: examples
                  - '--schema'
                  - inputPath: schema
                  - if:
                      cond:
                        isPresent: analyzer_cache
                      then:
                        - '--analyzer-cache'
                        - inputPath: analyzer_cache
                  - if:
                      cond:
                        isPresent: module_file
                      then:
                        - '--module-file'
                        - inputValue: module_file
                  - if:
                      cond:
                        isPresent: preprocessing_fn
                      then:
                        - '--preprocessing-fn'
                        - inputValue: preprocessing_fn
                  - if:
                      cond:
                        isPresent: force_tf_compat_v1
                      then:
                        - '--force-tf-compat-v1'
                        - inputValue: force_tf_compat_v1
                  - if:
                      cond:
                        isPresent: custom_config
                      then:
                        - '--custom-config'
                        - inputValue: custom_config
                  - if:
                      cond:
                        isPresent: splits_config
                      then:
                        - '--splits-config'
                        - inputValue: splits_config
                  - '--transform-graph'
                  - outputPath: transform_graph
                  - '--transformed-examples'
                  - outputPath: transformed_examples
                  - '--updated-analyzer-cache'
                  - outputPath: updated_analyzer_cache
        arguments:
          examples:
            taskOutput:
              taskId: CsvExampleGen
              outputName: examples
          schema:
            taskOutput:
              taskId: SchemaGen
              outputName: schema
          module_file: gs://avolkov/tensorflow-tfx-repo/v0.29.0/tfx/examples/chicago_taxi_pipeline/taxi_utils.py
        annotations:
          editor.position: '{"x":560,"y":610}'
      ExampleValidator:
        componentRef:
          digest: ecaeb3de4a47b68855bdd34b7ef14265651598ea28c74d5d6776ba73bd9f29e7
          url: https://raw.githubusercontent.com/kubeflow/pipelines/9b0d47a226c61f96e1ebe7a8ba427df38f8734e1/components/deprecated/tfx/ExampleValidator/component.yaml
          spec:
            name: ExampleValidator
            inputs:
              - name: statistics
                type: ExampleStatistics
              - name: schema
                type: Schema
              - name: exclude_splits
                type: String
                optional: true
            outputs:
              - name: anomalies
                type: ExampleAnomalies
            implementation:
              container:
                image: tensorflow/tfx:0.29.0
                command:
                  - sh
                  - '-ec'
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def _make_parent_dirs_and_return_path(file_path: str):
                        import os
                        os.makedirs(os.path.dirname(file_path), exist_ok=True)
                        return file_path

                    def ExampleValidator(
                        statistics_path,
                        schema_path,
                        anomalies_path,
                        exclude_splits = None,
                    ):
                        from tfx.components.example_validator.component import ExampleValidator as component_class

                        #Generated code
                        import os
                        import tempfile
                        from tensorflow.io import gfile
                        from google.protobuf import json_format, message
                        from tfx.types import channel_utils, artifact_utils
                        from tfx.components.base import base_executor

                        arguments = locals().copy()

                        component_class_args = {}

                        for name, execution_parameter in component_class.SPEC_CLASS.PARAMETERS.items():
                            argument_value = arguments.get(name, None)
                            if argument_value is None:
                                continue
                            parameter_type = execution_parameter.type
                            if isinstance(parameter_type, type) and issubclass(parameter_type, message.Message):
                                argument_value_obj = parameter_type()
                                json_format.Parse(argument_value, argument_value_obj)
                            else:
                                argument_value_obj = argument_value
                            component_class_args[name] = argument_value_obj

                        for name, channel_parameter in component_class.SPEC_CLASS.INPUTS.items():
                            artifact_path = arguments.get(name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel_parameter.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                if channel_parameter.type.PROPERTIES and 'split_names' in channel_parameter.type.PROPERTIES:
                                    # Recovering splits
                                    subdirs = gfile.listdir(artifact_path)
                                    # Workaround for https://github.com/tensorflow/tensorflow/issues/39167
                                    subdirs = [subdir.rstrip('/') for subdir in subdirs]
                                    split_names = [subdir.replace('Split-', '') for subdir in subdirs]
                                    artifact.split_names = artifact_utils.encode_split_names(sorted(split_names))
                                component_class_args[name] = channel_utils.as_channel([artifact])

                        component_class_instance = component_class(**component_class_args)

                        input_dict = channel_utils.unwrap_channel_dict(component_class_instance.inputs.get_all())
                        output_dict = {}
                        exec_properties = component_class_instance.exec_properties

                        # Generating paths for output artifacts
                        for name, channel in component_class_instance.outputs.items():
                            artifact_path = arguments.get('output_' + name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                artifact_list = [artifact]
                                channel._artifacts = artifact_list
                                output_dict[name] = artifact_list

                        print('component instance: ' + str(component_class_instance))

                        executor_context = base_executor.BaseExecutor.Context(
                            beam_pipeline_args=arguments.get('beam_pipeline_args'),
                            tmp_dir=tempfile.gettempdir(),
                            unique_id='tfx_component',
                        )
                        executor = component_class_instance.executor_spec.executor_class(executor_context)
                        executor.Do(
                            input_dict=input_dict,
                            output_dict=output_dict,
                            exec_properties=exec_properties,
                        )

                    import argparse
                    _parser = argparse.ArgumentParser(prog='ExampleValidator', description='')
                    _parser.add_argument("--statistics", dest="statistics_path", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--schema", dest="schema_path", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--exclude-splits", dest="exclude_splits", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--anomalies", dest="anomalies_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parsed_args = vars(_parser.parse_args())

                    _outputs = ExampleValidator(**_parsed_args)
                args:
                  - '--statistics'
                  - inputPath: statistics
                  - '--schema'
                  - inputPath: schema
                  - if:
                      cond:
                        isPresent: exclude_splits
                      then:
                        - '--exclude-splits'
                        - inputValue: exclude_splits
                  - '--anomalies'
                  - outputPath: anomalies
        arguments:
          statistics:
            taskOutput:
              taskId: StatisticsGen
              outputName: statistics
          schema:
            taskOutput:
              taskId: SchemaGen
              outputName: schema
        annotations:
          editor.position: '{"x":820,"y":0}'
      Trainer:
        componentRef:
          digest: 82fed18a7f27188ff17b9c9cfd532b8d1d183c2a2bb22ddcb0d48e86ecccdc23
          url: https://raw.githubusercontent.com/kubeflow/pipelines/9b0d47a226c61f96e1ebe7a8ba427df38f8734e1/components/deprecated/tfx/Trainer/component.yaml
          spec:
            name: Trainer
            inputs:
              - name: examples
                type: Examples
              - name: train_args
                type:
                  JsonObject:
                    data_type: proto:tfx.components.trainer.TrainArgs
              - name: eval_args
                type:
                  JsonObject:
                    data_type: proto:tfx.components.trainer.EvalArgs
              - name: transform_graph
                type: TransformGraph
                optional: true
              - name: schema
                type: Schema
                optional: true
              - name: base_model
                type: Model
                optional: true
              - name: hyperparameters
                type: HyperParameters
                optional: true
              - name: module_file
                type: String
                optional: true
              - name: run_fn
                type: String
                optional: true
              - name: trainer_fn
                type: String
                optional: true
              - name: custom_config
                type: String
                optional: true
            outputs:
              - name: model
                type: Model
              - name: model_run
                type: ModelRun
            implementation:
              container:
                image: tensorflow/tfx:0.29.0
                command:
                  - sh
                  - '-ec'
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def _make_parent_dirs_and_return_path(file_path: str):
                        import os
                        os.makedirs(os.path.dirname(file_path), exist_ok=True)
                        return file_path

                    def Trainer(
                        examples_path,
                        model_path,
                        model_run_path,
                        train_args,
                        eval_args,
                        transform_graph_path = None,
                        schema_path = None,
                        base_model_path = None,
                        hyperparameters_path = None,
                        module_file = None,
                        run_fn = None,
                        trainer_fn = None,
                        custom_config = None,
                    ):
                        from tfx.components.trainer.component import Trainer as component_class

                        #Generated code
                        import os
                        import tempfile
                        from tensorflow.io import gfile
                        from google.protobuf import json_format, message
                        from tfx.types import channel_utils, artifact_utils
                        from tfx.components.base import base_executor

                        arguments = locals().copy()

                        component_class_args = {}

                        for name, execution_parameter in component_class.SPEC_CLASS.PARAMETERS.items():
                            argument_value = arguments.get(name, None)
                            if argument_value is None:
                                continue
                            parameter_type = execution_parameter.type
                            if isinstance(parameter_type, type) and issubclass(parameter_type, message.Message):
                                argument_value_obj = parameter_type()
                                json_format.Parse(argument_value, argument_value_obj)
                            else:
                                argument_value_obj = argument_value
                            component_class_args[name] = argument_value_obj

                        for name, channel_parameter in component_class.SPEC_CLASS.INPUTS.items():
                            artifact_path = arguments.get(name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel_parameter.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                if channel_parameter.type.PROPERTIES and 'split_names' in channel_parameter.type.PROPERTIES:
                                    # Recovering splits
                                    subdirs = gfile.listdir(artifact_path)
                                    # Workaround for https://github.com/tensorflow/tensorflow/issues/39167
                                    subdirs = [subdir.rstrip('/') for subdir in subdirs]
                                    split_names = [subdir.replace('Split-', '') for subdir in subdirs]
                                    artifact.split_names = artifact_utils.encode_split_names(sorted(split_names))
                                component_class_args[name] = channel_utils.as_channel([artifact])

                        component_class_instance = component_class(**component_class_args)

                        input_dict = channel_utils.unwrap_channel_dict(component_class_instance.inputs.get_all())
                        output_dict = {}
                        exec_properties = component_class_instance.exec_properties

                        # Generating paths for output artifacts
                        for name, channel in component_class_instance.outputs.items():
                            artifact_path = arguments.get('output_' + name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                artifact_list = [artifact]
                                channel._artifacts = artifact_list
                                output_dict[name] = artifact_list

                        print('component instance: ' + str(component_class_instance))

                        executor_context = base_executor.BaseExecutor.Context(
                            beam_pipeline_args=arguments.get('beam_pipeline_args'),
                            tmp_dir=tempfile.gettempdir(),
                            unique_id='tfx_component',
                        )
                        executor = component_class_instance.executor_spec.executor_class(executor_context)
                        executor.Do(
                            input_dict=input_dict,
                            output_dict=output_dict,
                            exec_properties=exec_properties,
                        )

                    import argparse
                    _parser = argparse.ArgumentParser(prog='Trainer', description='')
                    _parser.add_argument("--examples", dest="examples_path", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--train-args", dest="train_args", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--eval-args", dest="eval_args", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--transform-graph", dest="transform_graph_path", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--schema", dest="schema_path", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--base-model", dest="base_model_path", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--hyperparameters", dest="hyperparameters_path", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--module-file", dest="module_file", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--run-fn", dest="run_fn", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--trainer-fn", dest="trainer_fn", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--custom-config", dest="custom_config", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--model", dest="model_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--model-run", dest="model_run_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parsed_args = vars(_parser.parse_args())

                    _outputs = Trainer(**_parsed_args)
                args:
                  - '--examples'
                  - inputPath: examples
                  - '--train-args'
                  - inputValue: train_args
                  - '--eval-args'
                  - inputValue: eval_args
                  - if:
                      cond:
                        isPresent: transform_graph
                      then:
                        - '--transform-graph'
                        - inputPath: transform_graph
                  - if:
                      cond:
                        isPresent: schema
                      then:
                        - '--schema'
                        - inputPath: schema
                  - if:
                      cond:
                        isPresent: base_model
                      then:
                        - '--base-model'
                        - inputPath: base_model
                  - if:
                      cond:
                        isPresent: hyperparameters
                      then:
                        - '--hyperparameters'
                        - inputPath: hyperparameters
                  - if:
                      cond:
                        isPresent: module_file
                      then:
                        - '--module-file'
                        - inputValue: module_file
                  - if:
                      cond:
                        isPresent: run_fn
                      then:
                        - '--run-fn'
                        - inputValue: run_fn
                  - if:
                      cond:
                        isPresent: trainer_fn
                      then:
                        - '--trainer-fn'
                        - inputValue: trainer_fn
                  - if:
                      cond:
                        isPresent: custom_config
                      then:
                        - '--custom-config'
                        - inputValue: custom_config
                  - '--model'
                  - outputPath: model
                  - '--model-run'
                  - outputPath: model_run
        arguments:
          examples:
            taskOutput:
              taskId: Transform
              outputName: transformed_examples
          train_args: '{"num_steps": 10000}'
          eval_args: '{"num_steps": 5000}'
          transform_graph:
            taskOutput:
              taskId: Transform
              outputName: transform_graph
          schema:
            taskOutput:
              taskId: SchemaGen
              outputName: schema
          module_file: gs://avolkov/tensorflow-tfx-repo/v0.29.0/tfx/examples/chicago_taxi_pipeline/taxi_utils.py
        annotations:
          editor.position: '{"x":1100,"y":730}'
      Evaluator:
        componentRef:
          digest: 769667bea1034068fc965937abbb127168d0bbca1815b73d2f7eade83423178b
          url: https://raw.githubusercontent.com/kubeflow/pipelines/9b0d47a226c61f96e1ebe7a8ba427df38f8734e1/components/deprecated/tfx/Evaluator/component.yaml
          spec:
            name: Evaluator
            inputs:
              - name: examples
                type: Examples
              - name: model
                type: Model
                optional: true
              - name: baseline_model
                type: Model
                optional: true
              - name: schema
                type: Schema
                optional: true
              - name: eval_config
                type:
                  JsonObject:
                    data_type: proto:tensorflow_model_analysis.EvalConfig
                optional: true
              - name: feature_slicing_spec
                type:
                  JsonObject:
                    data_type: proto:tfx.components.evaluator.FeatureSlicingSpec
                optional: true
              - name: fairness_indicator_thresholds
                type: JsonArray
                optional: true
              - name: example_splits
                type: String
                optional: true
              - name: module_file
                type: String
                optional: true
              - name: module_path
                type: String
                optional: true
            outputs:
              - name: evaluation
                type: ModelEvaluation
              - name: blessing
                type: ModelBlessing
            implementation:
              container:
                image: tensorflow/tfx:0.29.0
                command:
                  - sh
                  - '-ec'
                  - |
                    program_path=$(mktemp)
                    printf "%s" "$0" > "$program_path"
                    python3 -u "$program_path" "$@"
                  - |
                    def _make_parent_dirs_and_return_path(file_path: str):
                        import os
                        os.makedirs(os.path.dirname(file_path), exist_ok=True)
                        return file_path

                    def Evaluator(
                        examples_path,
                        evaluation_path,
                        blessing_path,
                        model_path = None,
                        baseline_model_path = None,
                        schema_path = None,
                        eval_config = None,
                        feature_slicing_spec = None,
                        fairness_indicator_thresholds = None,
                        example_splits = None,
                        module_file = None,
                        module_path = None,
                    ):
                        from tfx.components.evaluator.component import Evaluator as component_class

                        #Generated code
                        import os
                        import tempfile
                        from tensorflow.io import gfile
                        from google.protobuf import json_format, message
                        from tfx.types import channel_utils, artifact_utils
                        from tfx.components.base import base_executor

                        arguments = locals().copy()

                        component_class_args = {}

                        for name, execution_parameter in component_class.SPEC_CLASS.PARAMETERS.items():
                            argument_value = arguments.get(name, None)
                            if argument_value is None:
                                continue
                            parameter_type = execution_parameter.type
                            if isinstance(parameter_type, type) and issubclass(parameter_type, message.Message):
                                argument_value_obj = parameter_type()
                                json_format.Parse(argument_value, argument_value_obj)
                            else:
                                argument_value_obj = argument_value
                            component_class_args[name] = argument_value_obj

                        for name, channel_parameter in component_class.SPEC_CLASS.INPUTS.items():
                            artifact_path = arguments.get(name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel_parameter.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                if channel_parameter.type.PROPERTIES and 'split_names' in channel_parameter.type.PROPERTIES:
                                    # Recovering splits
                                    subdirs = gfile.listdir(artifact_path)
                                    # Workaround for https://github.com/tensorflow/tensorflow/issues/39167
                                    subdirs = [subdir.rstrip('/') for subdir in subdirs]
                                    split_names = [subdir.replace('Split-', '') for subdir in subdirs]
                                    artifact.split_names = artifact_utils.encode_split_names(sorted(split_names))
                                component_class_args[name] = channel_utils.as_channel([artifact])

                        component_class_instance = component_class(**component_class_args)

                        input_dict = channel_utils.unwrap_channel_dict(component_class_instance.inputs.get_all())
                        output_dict = {}
                        exec_properties = component_class_instance.exec_properties

                        # Generating paths for output artifacts
                        for name, channel in component_class_instance.outputs.items():
                            artifact_path = arguments.get('output_' + name + '_uri') or arguments.get(name + '_path')
                            if artifact_path:
                                artifact = channel.type()
                                artifact.uri = artifact_path.rstrip('/') + '/'  # Some TFX components require that the artifact URIs end with a slash
                                artifact_list = [artifact]
                                channel._artifacts = artifact_list
                                output_dict[name] = artifact_list

                        print('component instance: ' + str(component_class_instance))

                        executor_context = base_executor.BaseExecutor.Context(
                            beam_pipeline_args=arguments.get('beam_pipeline_args'),
                            tmp_dir=tempfile.gettempdir(),
                            unique_id='tfx_component',
                        )
                        executor = component_class_instance.executor_spec.executor_class(executor_context)
                        executor.Do(
                            input_dict=input_dict,
                            output_dict=output_dict,
                            exec_properties=exec_properties,
                        )

                    import json
                    import argparse
                    _parser = argparse.ArgumentParser(prog='Evaluator', description='')
                    _parser.add_argument("--examples", dest="examples_path", type=str, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--model", dest="model_path", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--baseline-model", dest="baseline_model_path", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--schema", dest="schema_path", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--eval-config", dest="eval_config", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--feature-slicing-spec", dest="feature_slicing_spec", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--fairness-indicator-thresholds", dest="fairness_indicator_thresholds", type=json.loads, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--example-splits", dest="example_splits", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--module-file", dest="module_file", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--module-path", dest="module_path", type=str, required=False, default=argparse.SUPPRESS)
                    _parser.add_argument("--evaluation", dest="evaluation_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parser.add_argument("--blessing", dest="blessing_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
                    _parsed_args = vars(_parser.parse_args())

                    _outputs = Evaluator(**_parsed_args)
                args:
                  - '--examples'
                  - inputPath: examples
                  - if:
                      cond:
                        isPresent: model
                      then:
                        - '--model'
                        - inputPath: model
                  - if:
                      cond:
                        isPresent: baseline_model
                      then:
                        - '--baseline-model'
                        - inputPath: baseline_model
                  - if:
                      cond:
                        isPresent: schema
                      then:
                        - '--schema'
                        - inputPath: schema
                  - if:
                      cond:
                        isPresent: eval_config
                      then:
                        - '--eval-config'
                        - inputValue: eval_config
                  - if:
                      cond:
                        isPresent: feature_slicing_spec
                      then:
                        - '--feature-slicing-spec'
                        - inputValue: feature_slicing_spec
                  - if:
                      cond:
                        isPresent: fairness_indicator_thresholds
                      then:
                        - '--fairness-indicator-thresholds'
                        - inputValue: fairness_indicator_thresholds
                  - if:
                      cond:
                        isPresent: example_splits
                      then:
                        - '--example-splits'
                        - inputValue: example_splits
                  - if:
                      cond:
                        isPresent: module_file
                      then:
                        - '--module-file'
                        - inputValue: module_file
                  - if:
                      cond:
                        isPresent: module_path
                      then:
                        - '--module-path'
                        - inputValue: module_path
                  - '--evaluation'
                  - outputPath: evaluation
                  - '--blessing'
                  - outputPath: blessing
        arguments:
          examples:
            taskOutput:
              taskId: CsvExampleGen
              outputName: examples
          model:
            taskOutput:
              taskId: Trainer
              outputName: model
          eval_config: '{"model_specs": [{"signature_name": "eval"}], "slicing_specs": [{}, {"feature_keys": ["trip_start_hour"]}], "metrics_specs": [{"thresholds": {"accuracy": {"value_threshold": {"lower_bound": 0.6}, "change_threshold": {"direction": 2, "absolute": -1e-10}}}}]}'
        annotations:
          editor.position: '{"x":1280,"y":370}'
